{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be889ea-8a2c-471c-8089-26494afcd02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "          if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff979cb9-8a0d-403f-b9e6-113f930f839f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper-param\n",
    "text_file = \"tiny-shakespeare.txt\"\n",
    "with open(text_file, \"r\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be475b4-b37e-4d97-a37f-a50b6a2da559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Proted Stajyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_device.py:77: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create a character-level vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "\n",
    "# Create mappings from characters to indices and vice versa\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "# Encode the entire text as integers\n",
    "encoded_text = np.array([char_to_idx[char] for char in text])\n",
    "\n",
    "# Define the sequence length\n",
    "seq_length = 100\n",
    "num_samples = len(encoded_text) // seq_length\n",
    "\n",
    "# Create input and target sequences\n",
    "input_sequences = []\n",
    "target_sequences = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    start_idx = i * seq_length\n",
    "    end_idx = start_idx + seq_length\n",
    "    input_sequences.append(encoded_text[start_idx:end_idx])\n",
    "    target_sequences.append(encoded_text[start_idx + 1:end_idx + 1])\n",
    "\n",
    "# Convert sequences to PyTorch tensors\n",
    "input_sequences = torch.tensor(input_sequences, dtype=torch.long)\n",
    "target_sequences = torch.tensor(target_sequences, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc6591f-9953-4200-a5a7-3c1ec25c682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18, 47, 56,  ..., 37, 53, 59],\n",
       "        [ 1, 39, 56,  ..., 63, 53, 59],\n",
       "        [ 1, 49, 52,  ...,  1, 59, 57],\n",
       "        ...,\n",
       "        [13, 26, 10,  ...,  1, 39,  1],\n",
       "        [57, 50, 43,  ..., 56, 43, 54],\n",
       "        [53, 57, 43,  ..., 21, 27, 10]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
