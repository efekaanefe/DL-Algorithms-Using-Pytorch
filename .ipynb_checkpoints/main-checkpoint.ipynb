{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dd4d36-609b-4e14-ba93-ebf08bdb15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Props to this sensei\n",
    "# https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a77eb7d-2891-46db-9649-70dbf52dd5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "          if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a483cfa-c20f-460b-b51c-7f2c8275853d",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b89ca760-851f-4cfc-b0f4-f6837de852cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"tiny-shakespeare.txt\"\n",
    "batch_size = 4 # how many blocks will be given to model\n",
    "block_size = 8 # context length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24e153-111f-490b-aa5f-9579bf99d022",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5123bdbe-4f29-476b-b2d3-2d142e5e7661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "with open(text_file, \"r\") as f:\n",
    "    text = f.read()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc14e1f1-3f5e-4e98-b838-cbbcb10b6585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the characters in the text: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Length of the characters: 65\n"
     ]
    }
   ],
   "source": [
    "char_list = sorted(list(set(text)))\n",
    "char_size = len(char_list)\n",
    "print(f\"All the characters in the text: {''.join(char_list)}\")\n",
    "print(f\"Length of the characters: {char_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe3542-8123-49f9-8ea7-2e070befb718",
   "metadata": {},
   "source": [
    "## Tokenizer (character based, index/ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adea02c-1c7f-4b68-8013-2c5a5666eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        self.char_to_index = None\n",
    "        self.index_to_char = None\n",
    "\n",
    "    def fit(self, char_list):  \n",
    "        self.char_to_index = {char: idx for idx, char in enumerate(char_list)}\n",
    "        self.index_to_char = {idx: char for char, idx in self.char_to_index.items()}\n",
    "\n",
    "    def encode_index(self, input_str):\n",
    "        return [self.char_to_index[char] for char in input_str]\n",
    "\n",
    "    def decode_index(self, encoded_list):\n",
    "        return ''.join([self.index_to_char[idx] for idx in encoded_list])\n",
    "\n",
    "    @staticmethod\n",
    "    def ascii_tokenizer(char):\n",
    "        return ord(char)\n",
    "\n",
    "    @staticmethod\n",
    "    def ascii_decoder(ascii_value):\n",
    "        return chr(ascii_value)\n",
    "\n",
    "    def encode_combined(self, input_str, use_ascii=False):\n",
    "        if use_ascii:\n",
    "            return [self.ascii_tokenizer(char) for char in input_str]\n",
    "        else:\n",
    "            return self.encode_index(input_str)\n",
    "\n",
    "    def decode_combined(self, encoded_list, use_ascii=False):\n",
    "        if use_ascii:\n",
    "            return ''.join([self.ascii_decoder(ascii_value) for ascii_value in encoded_list])\n",
    "        else:\n",
    "            return self.decode_index(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c755ae-b836-4c4d-982c-201b91bc9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String: Hello there\n",
      "Encoded List (ASCII): [72, 101, 108, 108, 111, 32, 116, 104, 101, 114, 101]\n",
      "Decoded String (ASCII): Hello there\n",
      "Encoded List (Index): [72, 101, 108, 108, 111, 32, 116, 104, 101, 114, 101]\n",
      "Decoded String (Index): Hello there\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tokenizer = MyTokenizer()\n",
    "tokenizer.fit(char_list)\n",
    "\n",
    "input_str = \"Hello there\"\n",
    "encoded_list_ascii = tokenizer.encode_combined(input_str, use_ascii=True)\n",
    "decoded_str_ascii = tokenizer.decode_combined(encoded_list_ascii, use_ascii=True)\n",
    "\n",
    "encoded_list_index = tokenizer.encode_combined(input_str, use_ascii=True)\n",
    "decoded_str_index = tokenizer.decode_combined(encoded_list_index, use_ascii=True)\n",
    "\n",
    "print(\"Original String:\", input_str)\n",
    "print(\"Encoded List (ASCII):\", encoded_list_ascii)\n",
    "print(\"Decoded String (ASCII):\", decoded_str_ascii)\n",
    "\n",
    "print(\"Encoded List (Index):\", encoded_list_index)\n",
    "print(\"Decoded String (Index):\", decoded_str_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3773c490-c37e-453a-8057-9fa02db53bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode all the data and split into train and val\n",
    "encoded_data = torch.tensor(tokenizer.encode_combined(text))\n",
    "n = int( 0.9 * len(encoded_data))\n",
    "\n",
    "train_data = encoded_data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03d43b2d-c173-45f8-906c-1c421933115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[0:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    \n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0dfeca6-9595-4419-9ff9-c32d5bd977ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "torch.Size([4, 8])\n",
      "tensor([[52, 45, 57, 58,  1, 58, 46, 43],\n",
      "        [47, 52, 49,  6,  0, 18, 53, 56],\n",
      "        [35, 43, 50, 41, 53, 51, 43,  6],\n",
      "        [25, 28, 17, 37, 10,  0, 20, 43]])\n",
      "targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[45, 57, 58,  1, 58, 46, 43, 51],\n",
      "        [52, 49,  6,  0, 18, 53, 56,  1],\n",
      "        [43, 50, 41, 53, 51, 43,  6,  1],\n",
      "        [28, 17, 37, 10,  0, 20, 43,  1]])\n",
      "when input is [52] the target: 45\n",
      "when input is [52, 45] the target: 57\n",
      "when input is [52, 45, 57] the target: 58\n",
      "when input is [52, 45, 57, 58] the target: 1\n",
      "when input is [52, 45, 57, 58, 1] the target: 58\n",
      "when input is [52, 45, 57, 58, 1, 58] the target: 46\n",
      "when input is [52, 45, 57, 58, 1, 58, 46] the target: 43\n",
      "when input is [52, 45, 57, 58, 1, 58, 46, 43] the target: 51\n",
      "when input is [47] the target: 52\n",
      "when input is [47, 52] the target: 49\n",
      "when input is [47, 52, 49] the target: 6\n",
      "when input is [47, 52, 49, 6] the target: 0\n",
      "when input is [47, 52, 49, 6, 0] the target: 18\n",
      "when input is [47, 52, 49, 6, 0, 18] the target: 53\n",
      "when input is [47, 52, 49, 6, 0, 18, 53] the target: 56\n",
      "when input is [47, 52, 49, 6, 0, 18, 53, 56] the target: 1\n",
      "when input is [35] the target: 43\n",
      "when input is [35, 43] the target: 50\n",
      "when input is [35, 43, 50] the target: 41\n",
      "when input is [35, 43, 50, 41] the target: 53\n",
      "when input is [35, 43, 50, 41, 53] the target: 51\n",
      "when input is [35, 43, 50, 41, 53, 51] the target: 43\n",
      "when input is [35, 43, 50, 41, 53, 51, 43] the target: 6\n",
      "when input is [35, 43, 50, 41, 53, 51, 43, 6] the target: 1\n",
      "when input is [25] the target: 28\n",
      "when input is [25, 28] the target: 17\n",
      "when input is [25, 28, 17] the target: 37\n",
      "when input is [25, 28, 17, 37] the target: 10\n",
      "when input is [25, 28, 17, 37, 10] the target: 0\n",
      "when input is [25, 28, 17, 37, 10, 0] the target: 20\n",
      "when input is [25, 28, 17, 37, 10, 0, 20] the target: 43\n",
      "when input is [25, 28, 17, 37, 10, 0, 20, 43] the target: 1\n"
     ]
    }
   ],
   "source": [
    "# batching\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y \n",
    "\n",
    "xb, yb = get_batch(\"train\") # xb -> input to the transformer\n",
    "print(\"inputs: \")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print(\"targets: \")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3768052-82ec-4f5e-bc95-0e8f7bcb61c2",
   "metadata": {},
   "source": [
    "## Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51206003-0d39-428b-b766-4c3a724b2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(char_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(tokenizer.decode_combined(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43202c3-4efd-44f0-99a8-8663cdbc3aa6",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d1d7c7-1c9c-4485-8bec-03ac33b217fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encoded_data)\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "897f99c6-677a-44c7-8b16-e51881ab0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cold.', (\"feel'st\", 'it')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[18, 47, 56, 57, 58, 1, 15, 47, 58]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encoded_data):\n",
    "        self.encoded_data = encoded_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_data[idx]\n",
    "        \n",
    "dataset = MyDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# printing the first batch\n",
    "for batch in dataloader: \n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa0211-1c19-49b4-b445-71407f87a237",
   "metadata": {},
   "source": [
    "# simple NGramModel using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "602ab944-7641-43d3-9aaf-326428c170d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "**********\n",
      "Loss: 5.353088\n",
      "epoch: 2\n",
      "**********\n",
      "Loss: 5.295852\n",
      "epoch: 3\n",
      "**********\n",
      "Loss: 5.239206\n",
      "epoch: 4\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EFO\\AppData\\Local\\Temp\\ipykernel_952\\3684268013.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_prob = F.log_softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.183216\n",
      "epoch: 5\n",
      "**********\n",
      "Loss: 5.127892\n",
      "epoch: 6\n",
      "**********\n",
      "Loss: 5.073198\n",
      "epoch: 7\n",
      "**********\n",
      "Loss: 5.018655\n",
      "epoch: 8\n",
      "**********\n",
      "Loss: 4.964472\n",
      "epoch: 9\n",
      "**********\n",
      "Loss: 4.910336\n",
      "epoch: 10\n",
      "**********\n",
      "Loss: 4.856346\n",
      "epoch: 11\n",
      "**********\n",
      "Loss: 4.802462\n",
      "epoch: 12\n",
      "**********\n",
      "Loss: 4.748453\n",
      "epoch: 13\n",
      "**********\n",
      "Loss: 4.694087\n",
      "epoch: 14\n",
      "**********\n",
      "Loss: 4.639548\n",
      "epoch: 15\n",
      "**********\n",
      "Loss: 4.584818\n",
      "epoch: 16\n",
      "**********\n",
      "Loss: 4.529846\n",
      "epoch: 17\n",
      "**********\n",
      "Loss: 4.474448\n",
      "epoch: 18\n",
      "**********\n",
      "Loss: 4.418889\n",
      "epoch: 19\n",
      "**********\n",
      "Loss: 4.362829\n",
      "epoch: 20\n",
      "**********\n",
      "Loss: 4.306433\n",
      "epoch: 21\n",
      "**********\n",
      "Loss: 4.249741\n",
      "epoch: 22\n",
      "**********\n",
      "Loss: 4.192754\n",
      "epoch: 23\n",
      "**********\n",
      "Loss: 4.135303\n",
      "epoch: 24\n",
      "**********\n",
      "Loss: 4.077417\n",
      "epoch: 25\n",
      "**********\n",
      "Loss: 4.019286\n",
      "epoch: 26\n",
      "**********\n",
      "Loss: 3.960602\n",
      "epoch: 27\n",
      "**********\n",
      "Loss: 3.901751\n",
      "epoch: 28\n",
      "**********\n",
      "Loss: 3.842317\n",
      "epoch: 29\n",
      "**********\n",
      "Loss: 3.782586\n",
      "epoch: 30\n",
      "**********\n",
      "Loss: 3.722470\n",
      "epoch: 31\n",
      "**********\n",
      "Loss: 3.661944\n",
      "epoch: 32\n",
      "**********\n",
      "Loss: 3.600804\n",
      "epoch: 33\n",
      "**********\n",
      "Loss: 3.539249\n",
      "epoch: 34\n",
      "**********\n",
      "Loss: 3.477202\n",
      "epoch: 35\n",
      "**********\n",
      "Loss: 3.414585\n",
      "epoch: 36\n",
      "**********\n",
      "Loss: 3.351345\n",
      "epoch: 37\n",
      "**********\n",
      "Loss: 3.287336\n",
      "epoch: 38\n",
      "**********\n",
      "Loss: 3.223087\n",
      "epoch: 39\n",
      "**********\n",
      "Loss: 3.158084\n",
      "epoch: 40\n",
      "**********\n",
      "Loss: 3.092922\n",
      "epoch: 41\n",
      "**********\n",
      "Loss: 3.027213\n",
      "epoch: 42\n",
      "**********\n",
      "Loss: 2.961054\n",
      "epoch: 43\n",
      "**********\n",
      "Loss: 2.894499\n",
      "epoch: 44\n",
      "**********\n",
      "Loss: 2.827987\n",
      "epoch: 45\n",
      "**********\n",
      "Loss: 2.760913\n",
      "epoch: 46\n",
      "**********\n",
      "Loss: 2.693770\n",
      "epoch: 47\n",
      "**********\n",
      "Loss: 2.626580\n",
      "epoch: 48\n",
      "**********\n",
      "Loss: 2.559182\n",
      "epoch: 49\n",
      "**********\n",
      "Loss: 2.491983\n",
      "epoch: 50\n",
      "**********\n",
      "Loss: 2.424614\n",
      "epoch: 51\n",
      "**********\n",
      "Loss: 2.357536\n",
      "epoch: 52\n",
      "**********\n",
      "Loss: 2.290609\n",
      "epoch: 53\n",
      "**********\n",
      "Loss: 2.224152\n",
      "epoch: 54\n",
      "**********\n",
      "Loss: 2.157922\n",
      "epoch: 55\n",
      "**********\n",
      "Loss: 2.092248\n",
      "epoch: 56\n",
      "**********\n",
      "Loss: 2.026921\n",
      "epoch: 57\n",
      "**********\n",
      "Loss: 1.962219\n",
      "epoch: 58\n",
      "**********\n",
      "Loss: 1.898465\n",
      "epoch: 59\n",
      "**********\n",
      "Loss: 1.835346\n",
      "epoch: 60\n",
      "**********\n",
      "Loss: 1.773211\n",
      "epoch: 61\n",
      "**********\n",
      "Loss: 1.711880\n",
      "epoch: 62\n",
      "**********\n",
      "Loss: 1.651707\n",
      "epoch: 63\n",
      "**********\n",
      "Loss: 1.592629\n",
      "epoch: 64\n",
      "**********\n",
      "Loss: 1.534680\n",
      "epoch: 65\n",
      "**********\n",
      "Loss: 1.478117\n",
      "epoch: 66\n",
      "**********\n",
      "Loss: 1.422885\n",
      "epoch: 67\n",
      "**********\n",
      "Loss: 1.369015\n",
      "epoch: 68\n",
      "**********\n",
      "Loss: 1.316572\n",
      "epoch: 69\n",
      "**********\n",
      "Loss: 1.265673\n",
      "epoch: 70\n",
      "**********\n",
      "Loss: 1.216244\n",
      "epoch: 71\n",
      "**********\n",
      "Loss: 1.168282\n",
      "epoch: 72\n",
      "**********\n",
      "Loss: 1.122103\n",
      "epoch: 73\n",
      "**********\n",
      "Loss: 1.077380\n",
      "epoch: 74\n",
      "**********\n",
      "Loss: 1.034322\n",
      "epoch: 75\n",
      "**********\n",
      "Loss: 0.992756\n",
      "epoch: 76\n",
      "**********\n",
      "Loss: 0.952962\n",
      "epoch: 77\n",
      "**********\n",
      "Loss: 0.914555\n",
      "epoch: 78\n",
      "**********\n",
      "Loss: 0.877779\n",
      "epoch: 79\n",
      "**********\n",
      "Loss: 0.842629\n",
      "epoch: 80\n",
      "**********\n",
      "Loss: 0.808805\n",
      "epoch: 81\n",
      "**********\n",
      "Loss: 0.776613\n",
      "epoch: 82\n",
      "**********\n",
      "Loss: 0.745832\n",
      "epoch: 83\n",
      "**********\n",
      "Loss: 0.716468\n",
      "epoch: 84\n",
      "**********\n",
      "Loss: 0.688459\n",
      "epoch: 85\n",
      "**********\n",
      "Loss: 0.661762\n",
      "epoch: 86\n",
      "**********\n",
      "Loss: 0.636375\n",
      "epoch: 87\n",
      "**********\n",
      "Loss: 0.612239\n",
      "epoch: 88\n",
      "**********\n",
      "Loss: 0.589243\n",
      "epoch: 89\n",
      "**********\n",
      "Loss: 0.567416\n",
      "epoch: 90\n",
      "**********\n",
      "Loss: 0.546699\n",
      "epoch: 91\n",
      "**********\n",
      "Loss: 0.526999\n",
      "epoch: 92\n",
      "**********\n",
      "Loss: 0.508289\n",
      "epoch: 93\n",
      "**********\n",
      "Loss: 0.490552\n",
      "epoch: 94\n",
      "**********\n",
      "Loss: 0.473738\n",
      "epoch: 95\n",
      "**********\n",
      "Loss: 0.457711\n",
      "epoch: 96\n",
      "**********\n",
      "Loss: 0.442548\n",
      "epoch: 97\n",
      "**********\n",
      "Loss: 0.428140\n",
      "epoch: 98\n",
      "**********\n",
      "Loss: 0.414454\n",
      "epoch: 99\n",
      "**********\n",
      "Loss: 0.401455\n",
      "epoch: 100\n",
      "**********\n",
      "Loss: 0.389106\n",
      "real word is thy, predict word is thy\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "test_sentence = text.split()\n",
    "\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "\n",
    "trigram = [((test_sentence[i], test_sentence[i + 1]), test_sentence[i + 2])for i in range(len(test_sentence) - 2)]\n",
    "\n",
    "vocb = set(test_sentence)\n",
    "word_to_idx = {word: i for i, word in enumerate(vocb)}\n",
    "idx_to_word = {word_to_idx[word]: word for word in word_to_idx}\n",
    "\n",
    "class NgramModel(nn.Module):\n",
    "    def __init__(self, vocb_size, context_size, n_dim):\n",
    "        super(NgramModel, self).__init__()\n",
    "        self.n_word = vocb_size\n",
    "        self.embedding = nn.Embedding(self.n_word, n_dim)\n",
    "        self.linear1 = nn.Linear(context_size * n_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, self.n_word)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        emb = emb.view(1, -1)\n",
    "        out = self.linear1(emb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        log_prob = F.log_softmax(out)\n",
    "        return log_prob\n",
    "\n",
    "ngrammodel = NgramModel(len(word_to_idx), CONTEXT_SIZE, 100)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(ngrammodel.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('epoch: {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0\n",
    "    for data in trigram:\n",
    "        word, label = data\n",
    "        word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n",
    "        label = Variable(torch.LongTensor([word_to_idx[label]]))\n",
    "        # forward\n",
    "        out = ngrammodel(word)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item()\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Loss: {:.6f}'.format(running_loss / len(word_to_idx)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac61e97-f71a-4d80-9ef0-7f9f69eec3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 76])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f0db54-291a-4284-9ca8-c05524104e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real word is thy, predict word is thy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EFO\\AppData\\Local\\Temp\\ipykernel_952\\3684268013.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_prob = F.log_softmax(out)\n"
     ]
    }
   ],
   "source": [
    "word, label = trigram[3]\n",
    "word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n",
    "out = ngrammodel(word)\n",
    "_, predict_label = torch.max(out, 1)\n",
    "predict_word = idx_to_word[predict_label.item()]\n",
    "print('real word is {}, predict word is {}'.format(label, predict_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534c75-0447-4a1f-98f1-e00bf209d784",
   "metadata": {},
   "source": [
    "## GPT and language models\n",
    "https://github.com/iVishalr/GPT/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9954e-c3f3-46ed-9ed4-ef5b5716a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@mingzehe/implement-transformer-via-pytorch-step-by-step-part-2-69f020d580c6\n",
    "\n",
    "#attention \n",
    "def attention(k,q,v):\n",
    "    # q dim [batch_size,n_heads,length,d_tensor]\n",
    "    d_tensor = q.size(-1) \n",
    "    # assume dim of query/key/value vector should be same \n",
    "    # and it should be to make below calculation happen      \n",
    "    k_t = k.transpose(-2,-1) #[batch_size,n_heads,d_tensor,length]\n",
    "    score = (q @ k_t)/math.sqrt(d_tensor)\n",
    "    v= torch.softmax(score,dim=-1) @ v\n",
    "    return v,score\n",
    "\n",
    "import copy\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "  # reduced dim for each Q,K,V, but added up to d_model\n",
    "        self.d_k = d_model // n_head \n",
    "        self.n_head = n_head\n",
    "        self.attn = None\n",
    "  # use the attention class defined above\n",
    "        self.attention = attention() \n",
    "\n",
    "  # 3 for K,Q,V, the forth layer is on the top for final attention score\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4) \n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        samples = q.size(0) #q init as 512x512\n",
    "    # split tensor by number of heads\n",
    "        q, k, v = [   lin(x).view(samples, -1, self.n_head, self.d_k).transpose(1, 2)\n",
    "    # [512,512] => [512,1,8,64] => [512,8,1,64] now we have 8 heads, \n",
    "    #length 1 since conv of size 1, dim of 64 for each q,k,v, \n",
    "    #ready for input to attention [batch_size, head, length, d_tensor]\n",
    "            for lin, x in zip(self.linears, (q, k, v)) \n",
    "    # we only used 3 first linear layers since zip would \n",
    "        ]\n",
    "        \n",
    "    # calculate the attention score \n",
    "        x, self.attn = attention(q, k, v)\n",
    "\n",
    "    # concat by view func [512, 8, 1, 64] => [512,1,512] add it back to 512\n",
    "        x = (x.transpose(1, 2).contiguous().view(samples, -1, self.n_head * self.d_k))\n",
    "    # now apply the final linear layer copy\n",
    "        return self.linears[-1](x) \n",
    "   \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,n_head,d_model,hidden):\n",
    "        super(Encoder_layer, self).__init__()\n",
    "        self.norm = nn.LayerNorm(layer.size)\n",
    "        self.attention_layer= MultiHeadAttention(d_model, n_head)\n",
    "        self.feed_forward_layer= FeedForwardLayer(d_model, hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # we make a copy for later residue adding\n",
    "        _x = x\n",
    "        # use multi-head attention we defined in part 1\n",
    "        atten = self.attention_layer(x)\n",
    "        # add residue and normalize layer\n",
    "        _atten = _x + self.norm(atten)\n",
    "        # feed forward layer which we will define later \n",
    "        x = self.feed_forward_layer(x)\n",
    "        return self.norm(x)+_atten\n",
    "\n",
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, d_model, hidden):\n",
    "        super(FeedForwardLayer, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, hidden, n_head, n_copy):\n",
    "        super().__init__()\n",
    "        # n_copy = 6 \n",
    "        self.layers = clones(EncoderLayer(d_model,hidden,n_head), n_copy)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # init as 515x512 matrix to make adding pos with input possible\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        # produce 0 to 511 pos index \n",
    "        pos = torch.arange(0, max_len)\n",
    "        # convert to 512x1 size\n",
    "        pos = pos.float().unsqueeze(dim=1)\n",
    "        # pick 0,2,4...etc 256 even numbers, \n",
    "        # _2i refers to the index in above formula\n",
    "        _2i = torch.arange(0, d_model, step=2).float()\n",
    "        # pos index (512,1) divide by _2i (256)\n",
    "        # broadcasting to (512,256), so every even column apply sin func\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        # odd column go through cos func\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size() \n",
    "        #now to apply encoding\n",
    "        return self.encoding[:seq_len, :]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a1491-ad9b-4dd2-8519-4c9dfb1ce480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "        # LSTM layers\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        # Output layer\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "# Example usage:\n",
    "# Set your vocabulary size, embedding dimension, hidden dimension, and number of LSTM layers\n",
    "vocab_size = 100  # replace with the actual size of your vocabulary\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "\n",
    "# Create an instance of the SimpleLanguageModel\n",
    "model = SimpleLanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e24a61-88ef-458a-b63f-ee9821484618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as some_file:\n",
    "        return [unicodeToAscii(line.strip()) for line in some_file]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# ``LongTensor`` of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = torch.Tensor([0]) # you can also just simply use ``loss = 0``\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every ``plot_every`` ``iters``\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2f3d4-8c25-4d5d-9487-5d505492c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "\n",
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))\n",
    "\n",
    "samples('Russian', 'RUS')\n",
    "\n",
    "samples('German', 'GER')\n",
    "\n",
    "samples('Spanish', 'SPA')\n",
    "\n",
    "samples('Chinese', 'CHI')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
