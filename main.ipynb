{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dd4d36-609b-4e14-ba93-ebf08bdb15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Props to this sensei\n",
    "# https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a77eb7d-2891-46db-9649-70dbf52dd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm # progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a483cfa-c20f-460b-b51c-7f2c8275853d",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b89ca760-851f-4cfc-b0f4-f6837de852cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "text_file = \"tiny-shakespeare.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24e153-111f-490b-aa5f-9579bf99d022",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5123bdbe-4f29-476b-b2d3-2d142e5e7661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "with open(text_file, \"r\") as f:\n",
    "    text = f.read()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc14e1f1-3f5e-4e98-b838-cbbcb10b6585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the characters in the text: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Length of the characters: 65\n"
     ]
    }
   ],
   "source": [
    "char_list = sorted(list(set(text)))\n",
    "char_size = len(char_list)\n",
    "print(f\"All the characters in the text: {''.join(char_list)}\")\n",
    "print(f\"Length of the characters: {char_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe3542-8123-49f9-8ea7-2e070befb718",
   "metadata": {},
   "source": [
    "## Tokenizer (character based, index/ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7adea02c-1c7f-4b68-8013-2c5a5666eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        self.char_to_index = None\n",
    "        self.index_to_char = None\n",
    "\n",
    "    def fit(self, char_list):  \n",
    "        self.char_to_index = {char: idx for idx, char in enumerate(char_list)}\n",
    "        self.index_to_char = {idx: char for char, idx in self.char_to_index.items()}\n",
    "\n",
    "    def encode_index(self, input_str):\n",
    "        return [self.char_to_index[char] for char in input_str]\n",
    "\n",
    "    def decode_index(self, encoded_list):\n",
    "        return ''.join([self.index_to_char[idx] for idx in encoded_list])\n",
    "\n",
    "    @staticmethod\n",
    "    def ascii_tokenizer(char):\n",
    "        return ord(char)\n",
    "\n",
    "    @staticmethod\n",
    "    def ascii_decoder(ascii_value):\n",
    "        return chr(ascii_value)\n",
    "\n",
    "    def encode_combined(self, input_str, use_ascii=False):\n",
    "        if use_ascii:\n",
    "            return [self.ascii_tokenizer(char) for char in input_str]\n",
    "        else:\n",
    "            return self.encode_index(input_str)\n",
    "\n",
    "    def decode_combined(self, encoded_list, use_ascii=False):\n",
    "        if use_ascii:\n",
    "            return ''.join([self.ascii_decoder(ascii_value) for ascii_value in encoded_list])\n",
    "        else:\n",
    "            return self.decode_index(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c755ae-b836-4c4d-982c-201b91bc9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String: Hello there\n",
      "Encoded List (ASCII): [72, 101, 108, 108, 111, 32, 116, 104, 101, 114, 101]\n",
      "Decoded String (ASCII): Hello there\n",
      "Encoded List (Index): [72, 101, 108, 108, 111, 32, 116, 104, 101, 114, 101]\n",
      "Decoded String (Index): Hello there\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tokenizer = MyTokenizer()\n",
    "tokenizer.fit(char_list)\n",
    "\n",
    "input_str = \"Hello there\"\n",
    "encoded_list_ascii = tokenizer.encode_combined(input_str, use_ascii=True)\n",
    "decoded_str_ascii = tokenizer.decode_combined(encoded_list_ascii, use_ascii=True)\n",
    "\n",
    "encoded_list_index = tokenizer.encode_combined(input_str, use_ascii=True)\n",
    "decoded_str_index = tokenizer.decode_combined(encoded_list_index, use_ascii=True)\n",
    "\n",
    "print(\"Original String:\", input_str)\n",
    "print(\"Encoded List (ASCII):\", encoded_list_ascii)\n",
    "print(\"Decoded String (ASCII):\", decoded_str_ascii)\n",
    "\n",
    "print(\"Encoded List (Index):\", encoded_list_index)\n",
    "print(\"Decoded String (Index):\", decoded_str_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3773c490-c37e-453a-8057-9fa02db53bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode all the data \n",
    "encoded_data = tokenizer.encode_combined(text) \n",
    "encoded_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43202c3-4efd-44f0-99a8-8663cdbc3aa6",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d1d7c7-1c9c-4485-8bec-03ac33b217fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encoded_data)\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "897f99c6-677a-44c7-8b16-e51881ab0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([37, 42, 46, 47, 54, 47, 43,  1, 60, 43, 10,  1, 52, 44,  1, 63, 52, 50,\n",
      "        58, 17, 43, 43, 52,  5, 47,  1, 32, 52, 43,  1, 58, 10, 53, 61, 52,  1,\n",
      "        45,  1, 56, 52, 43, 51, 26,  1, 57, 39,  1, 56,  1, 51, 21, 12, 10, 43,\n",
      "        47, 53, 53, 46, 60,  0, 39, 39, 58, 41])\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encoded_data):\n",
    "        self.encoded_data = encoded_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_data[idx]\n",
    "        \n",
    "dataset = MyDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# printing the first batch\n",
    "for batch in dataloader: \n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534c75-0447-4a1f-98f1-e00bf209d784",
   "metadata": {},
   "source": [
    "## GPT and language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9954e-c3f3-46ed-9ed4-ef5b5716a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@mingzehe/implement-transformer-via-pytorch-step-by-step-part-2-69f020d580c6\n",
    "\n",
    "class Encoder_layer(nn.Module):\n",
    "\n",
    "    def __init__(self,n_head,d_model,hidden):\n",
    "        super(Encoder_layer, self).__init__()\n",
    "        self.norm = nn.LayerNorm(layer.size)\n",
    "        self.attention_layer= MultiHeadAttention(d_model, n_head)\n",
    "        self.feed_forward_layer= FeedForwardLayer(d_model, hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # we make a copy for later residue adding\n",
    "        _x = x\n",
    "        # use multi-head attention we defined in part 1\n",
    "        atten = self.attention_layer(x)\n",
    "        # add residue and normalize layer\n",
    "        _atten = _x + self.norm(atten)\n",
    "        # feed forward layer which we will define later \n",
    "        x = self.feed_forward_layer(x)\n",
    "        return self.norm(x)+_atten\n",
    "\n",
    "class FeedForwardLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, hidden):\n",
    "        super(FeedForwardLayer, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, hidden, n_head, n_copy):\n",
    "        super().__init__()\n",
    "        # n_copy = 6 \n",
    "        self.layers = clones(EncoderLayer(d_model,hidden,n_head), n_copy)\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7179d81-e78a-43c0-a6d2-917e8f957426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "def forward(self, src):\n",
    "        src2 = self.self_attn(src, src, src)[0]\n",
    "        src = src + self.dropout(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(torch.relu(self.linear1(src))))\n",
    "        src = src + self.dropout(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([encoder_layer() for _ in range(num_layers)])\n",
    "    def forward(self, src):\n",
    "        for layer in self.layers:\n",
    "            src = layer(src)\n",
    "        return src\n",
    "\n",
    "d_model = 512  # Adjust according to your requirements\n",
    "nhead = 8\n",
    "num_layers = 6\n",
    "transformer_model = TransformerEncoder(TransformerEncoderLayer(d_model, nhead), num_layers)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:  # Iterate over your data batches\n",
    "        inputs, targets = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = transformer_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19aed417-537f-4149-89e0-dd937587ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (embedding): Embedding(10000, 256)\n",
      "  (transformer_layers): ModuleList(\n",
      "    (0-5): 6 x TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_heads, num_layers):\n",
    "        super(GPTModel, self).__init__()\n",
    "\n",
    "        # Token embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = self.create_positional_encoding(embedding_dim)\n",
    "\n",
    "        # Transformer layers\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Fully connected layer for prediction\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Token embedding\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # Add positional encoding\n",
    "        positional_encoded = embedded + self.positional_encoding[:embedded.size(0), :]\n",
    "\n",
    "        # Transformer layers\n",
    "        transformer_output = positional_encoded\n",
    "        for layer in self.transformer_layers:\n",
    "            transformer_output = layer(transformer_output)\n",
    "\n",
    "        # Fully connected layer for prediction\n",
    "        output = self.fc(transformer_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def create_positional_encoding(self, d_model, max_len=512):\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        positional_encoding = torch.zeros((max_len, d_model))\n",
    "        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        return positional_encoding\n",
    "\n",
    "# Example usage:\n",
    "vocab_size = 10000  # replace with your vocabulary size\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "\n",
    "model = GPTModel(vocab_size, embedding_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "413a1491-ad9b-4dd2-8519-4c9dfb1ce480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLanguageModel(\n",
      "  (embedding): Embedding(100, 64)\n",
      "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # LSTM layers\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "# Example usage:\n",
    "# Set your vocabulary size, embedding dimension, hidden dimension, and number of LSTM layers\n",
    "vocab_size = 100  # replace with the actual size of your vocabulary\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "\n",
    "# Create an instance of the SimpleLanguageModel\n",
    "model = SimpleLanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f2f3d4-8c25-4d5d-9487-5d505492c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "          if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
