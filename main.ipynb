{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dd4d36-609b-4e14-ba93-ebf08bdb15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Props to this sensei\n",
    "# https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a77eb7d-2891-46db-9649-70dbf52dd5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "          if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a483cfa-c20f-460b-b51c-7f2c8275853d",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89ca760-851f-4cfc-b0f4-f6837de852cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "text_file = \"tiny-shakespeare.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24e153-111f-490b-aa5f-9579bf99d022",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5123bdbe-4f29-476b-b2d3-2d142e5e7661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "with open(text_file, \"r\") as f:\n",
    "    text = f.read()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc14e1f1-3f5e-4e98-b838-cbbcb10b6585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the characters in the text: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Length of the characters: 65\n"
     ]
    }
   ],
   "source": [
    "char_list = sorted(list(set(text)))\n",
    "char_size = len(char_list)\n",
    "print(f\"All the characters in the text: {''.join(char_list)}\")\n",
    "print(f\"Length of the characters: {char_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe3542-8123-49f9-8ea7-2e070befb718",
   "metadata": {},
   "source": [
    "## Tokenizer (character based, index/ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adea02c-1c7f-4b68-8013-2c5a5666eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        self.char_to_index = None\n",
    "        self.index_to_char = None\n",
    "\n",
    "    def fit(self, char_list):  \n",
    "        self.char_to_index = {char: idx for idx, char in enumerate(char_list)}\n",
    "        self.index_to_char = {idx: char for char, idx in self.char_to_index.items()}\n",
    "\n",
    "    def encode_index(self, input_str):\n",
    "        return [self.char_to_index[char] for char in input_str]\n",
    "\n",
    "    def decode_index(self, encoded_list):\n",
    "        return ''.join([self.index_to_char[idx] for idx in encoded_list])\n",
    "\n",
    "    @staticmethod\n",
    "    def ascii_tokenizer(char):\n",
    "        return ord(char)\n",
    "\n",
    "    @staticmethod\n",
    "    def ascii_decoder(ascii_value):\n",
    "        return chr(ascii_value)\n",
    "\n",
    "    def encode_combined(self, input_str, use_ascii=False):\n",
    "        if use_ascii:\n",
    "            return [self.ascii_tokenizer(char) for char in input_str]\n",
    "        else:\n",
    "            return self.encode_index(input_str)\n",
    "\n",
    "    def decode_combined(self, encoded_list, use_ascii=False):\n",
    "        if use_ascii:\n",
    "            return ''.join([self.ascii_decoder(ascii_value) for ascii_value in encoded_list])\n",
    "        else:\n",
    "            return self.decode_index(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c755ae-b836-4c4d-982c-201b91bc9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String: Hello there\n",
      "Encoded List (ASCII): [72, 101, 108, 108, 111, 32, 116, 104, 101, 114, 101]\n",
      "Decoded String (ASCII): Hello there\n",
      "Encoded List (Index): [72, 101, 108, 108, 111, 32, 116, 104, 101, 114, 101]\n",
      "Decoded String (Index): Hello there\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tokenizer = MyTokenizer()\n",
    "tokenizer.fit(char_list)\n",
    "\n",
    "input_str = \"Hello there\"\n",
    "encoded_list_ascii = tokenizer.encode_combined(input_str, use_ascii=True)\n",
    "decoded_str_ascii = tokenizer.decode_combined(encoded_list_ascii, use_ascii=True)\n",
    "\n",
    "encoded_list_index = tokenizer.encode_combined(input_str, use_ascii=True)\n",
    "decoded_str_index = tokenizer.decode_combined(encoded_list_index, use_ascii=True)\n",
    "\n",
    "print(\"Original String:\", input_str)\n",
    "print(\"Encoded List (ASCII):\", encoded_list_ascii)\n",
    "print(\"Decoded String (ASCII):\", decoded_str_ascii)\n",
    "\n",
    "print(\"Encoded List (Index):\", encoded_list_index)\n",
    "print(\"Decoded String (Index):\", decoded_str_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3773c490-c37e-453a-8057-9fa02db53bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode all the data \n",
    "encoded_data = tokenizer.encode_combined(text) \n",
    "encoded_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43202c3-4efd-44f0-99a8-8663cdbc3aa6",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d1d7c7-1c9c-4485-8bec-03ac33b217fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encoded_data)\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897f99c6-677a-44c7-8b16-e51881ab0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([61,  1, 28,  1, 21, 12, 24, 50,  1,  1,  1, 52, 44, 14,  1,  1, 58, 51,\n",
      "        33,  1,  1,  1, 58, 39, 50, 52, 43, 58, 40,  0,  1, 27,  1, 58,  1, 58,\n",
      "        43, 56, 56, 14, 46, 30,  6, 19, 43, 20, 42, 43,  6, 32,  0,  1, 10, 56,\n",
      "        53, 42, 56, 47, 47, 63, 53, 47, 43, 63])\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encoded_data):\n",
    "        self.encoded_data = encoded_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_data[idx]\n",
    "        \n",
    "dataset = MyDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# printing the first batch\n",
    "for batch in dataloader: \n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534c75-0447-4a1f-98f1-e00bf209d784",
   "metadata": {},
   "source": [
    "## GPT and language models\n",
    "https://github.com/iVishalr/GPT/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a9954e-c3f3-46ed-9ed4-ef5b5716a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@mingzehe/implement-transformer-via-pytorch-step-by-step-part-2-69f020d580c6\n",
    "\n",
    "#attention \n",
    "def attention(k,q,v):\n",
    "    # q dim [batch_size,n_heads,length,d_tensor]\n",
    "    d_tensor = q.size(-1) \n",
    "    # assume dim of query/key/value vector should be same \n",
    "    # and it should be to make below calculation happen      \n",
    "    k_t = k.transpose(-2,-1) #[batch_size,n_heads,d_tensor,length]\n",
    "    score = (q @ k_t)/math.sqrt(d_tensor)\n",
    "    v= torch.softmax(score,dim=-1) @ v\n",
    "    return v,score\n",
    "\n",
    "import copy\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "  # reduced dim for each Q,K,V, but added up to d_model\n",
    "        self.d_k = d_model // n_head \n",
    "        self.n_head = n_head\n",
    "        self.attn = None\n",
    "  # use the attention class defined above\n",
    "        self.attention = attention() \n",
    "\n",
    "  # 3 for K,Q,V, the forth layer is on the top for final attention score\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4) \n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        samples = q.size(0) #q init as 512x512\n",
    "    # split tensor by number of heads\n",
    "        q, k, v = [   lin(x).view(samples, -1, self.n_head, self.d_k).transpose(1, 2)\n",
    "    # [512,512] => [512,1,8,64] => [512,8,1,64] now we have 8 heads, \n",
    "    #length 1 since conv of size 1, dim of 64 for each q,k,v, \n",
    "    #ready for input to attention [batch_size, head, length, d_tensor]\n",
    "            for lin, x in zip(self.linears, (q, k, v)) \n",
    "    # we only used 3 first linear layers since zip would \n",
    "        ]\n",
    "        \n",
    "    # calculate the attention score \n",
    "        x, self.attn = attention(q, k, v)\n",
    "\n",
    "    # concat by view func [512, 8, 1, 64] => [512,1,512] add it back to 512\n",
    "        x = (x.transpose(1, 2).contiguous().view(samples, -1, self.n_head * self.d_k))\n",
    "    # now apply the final linear layer copy\n",
    "        return self.linears[-1](x) \n",
    "   \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,n_head,d_model,hidden):\n",
    "        super(Encoder_layer, self).__init__()\n",
    "        self.norm = nn.LayerNorm(layer.size)\n",
    "        self.attention_layer= MultiHeadAttention(d_model, n_head)\n",
    "        self.feed_forward_layer= FeedForwardLayer(d_model, hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # we make a copy for later residue adding\n",
    "        _x = x\n",
    "        # use multi-head attention we defined in part 1\n",
    "        atten = self.attention_layer(x)\n",
    "        # add residue and normalize layer\n",
    "        _atten = _x + self.norm(atten)\n",
    "        # feed forward layer which we will define later \n",
    "        x = self.feed_forward_layer(x)\n",
    "        return self.norm(x)+_atten\n",
    "\n",
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, d_model, hidden):\n",
    "        super(FeedForwardLayer, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, hidden, n_head, n_copy):\n",
    "        super().__init__()\n",
    "        # n_copy = 6 \n",
    "        self.layers = clones(EncoderLayer(d_model,hidden,n_head), n_copy)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # init as 515x512 matrix to make adding pos with input possible\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        # produce 0 to 511 pos index \n",
    "        pos = torch.arange(0, max_len)\n",
    "        # convert to 512x1 size\n",
    "        pos = pos.float().unsqueeze(dim=1)\n",
    "        # pick 0,2,4...etc 256 even numbers, \n",
    "        # _2i refers to the index in above formula\n",
    "        _2i = torch.arange(0, d_model, step=2).float()\n",
    "        # pos index (512,1) divide by _2i (256)\n",
    "        # broadcasting to (512,256), so every even column apply sin func\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        # odd column go through cos func\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size() \n",
    "        #now to apply encoding\n",
    "        return self.encoding[:seq_len, :]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19aed417-537f-4149-89e0-dd937587ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (embedding): Embedding(10000, 256)\n",
      "  (transformer_layers): ModuleList(\n",
      "    (0-5): 6 x TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_heads, num_layers):\n",
    "        super(GPTModel, self).__init__()\n",
    "\n",
    "        # Token embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = self.create_positional_encoding(embedding_dim)\n",
    "\n",
    "        # Transformer layers\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Fully connected layer for prediction\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Token embedding\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # Add positional encoding\n",
    "        positional_encoded = embedded + self.positional_encoding[:embedded.size(0), :]\n",
    "\n",
    "        # Transformer layers\n",
    "        transformer_output = positional_encoded\n",
    "        for layer in self.transformer_layers:\n",
    "            transformer_output = layer(transformer_output)\n",
    "\n",
    "        # Fully connected layer for prediction\n",
    "        output = self.fc(transformer_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def create_positional_encoding(self, d_model, max_len=512):\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        positional_encoding = torch.zeros((max_len, d_model))\n",
    "        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        return positional_encoding\n",
    "\n",
    "# Example usage:\n",
    "vocab_size = 10000  # replace with your vocabulary size\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "\n",
    "model = GPTModel(vocab_size, embedding_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "913e9f3d-e4ae-4664-bdb5-a6fb3d5682c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (64) to match target batch_size (999).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m output_logits \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (64) to match target batch_size (999)."
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = [\"This is an example sentence.\", \"Another example here.\"]\n",
    "training_data = text[:1000]\n",
    "\n",
    "# Tokenize the dataset\n",
    "# tokenized_data = encoded_data\n",
    "\n",
    "tokenized_data = tokenizer.encode_combined(training_data) \n",
    "\n",
    "# Create an instance of the GPT model\n",
    "model = GPTModel(vocab_size, embedding_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for batch in dataloader:\n",
    "\n",
    "        inpu\n",
    "        # Forward pass\n",
    "        output_logits = model(input_tensor)\n",
    "    \n",
    "        # Calculate loss\n",
    "        loss = criterion(output_logits.view(-1, vocab_size), target_tensor)\n",
    "    \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fcd2b-3e77-4dcf-8147-f4574cc656c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference after training\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate text from a seed input\n",
    "    seed_text = ''\n",
    "    seed_tokenized = tokenizer.encode_combined(seed_text)\n",
    "    input_tensor = torch.tensor(seed_tokenized).unsqueeze(0)\n",
    "    generated_indices = torch.argmax(model(input_tensor), dim=-1).squeeze().tolist()\n",
    "    generated_text = tokenizer.decode_combined(generated_indices) \n",
    "\n",
    "    print(\"Generated Text:\", ''.join(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a1491-ad9b-4dd2-8519-4c9dfb1ce480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "        # LSTM layers\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        # Output layer\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "# Example usage:\n",
    "# Set your vocabulary size, embedding dimension, hidden dimension, and number of LSTM layers\n",
    "vocab_size = 100  # replace with the actual size of your vocabulary\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "\n",
    "# Create an instance of the SimpleLanguageModel\n",
    "model = SimpleLanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08e24a61-88ef-458a-b63f-ee9821484618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "O'Neal\n",
      "0m 16s (5000 5%) 3.4128\n",
      "0m 33s (10000 10%) 2.7357\n",
      "0m 50s (15000 15%) 2.1298\n",
      "1m 8s (20000 20%) 1.4868\n",
      "1m 24s (25000 25%) 1.8462\n",
      "1m 41s (30000 30%) 2.4166\n",
      "1m 57s (35000 35%) 2.3470\n",
      "2m 15s (40000 40%) 2.4300\n",
      "2m 32s (45000 45%) 2.7701\n",
      "2m 49s (50000 50%) 1.8545\n",
      "3m 6s (55000 55%) 1.7337\n",
      "3m 23s (60000 60%) 3.3119\n",
      "3m 40s (65000 65%) 3.2292\n",
      "3m 58s (70000 70%) 2.7137\n",
      "4m 16s (75000 75%) 2.3650\n",
      "4m 34s (80000 80%) 2.9670\n",
      "4m 51s (85000 85%) 2.5167\n",
      "5m 9s (90000 90%) 1.6618\n",
      "5m 25s (95000 95%) 1.5570\n",
      "5m 42s (100000 100%) 3.3716\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as some_file:\n",
    "        return [unicodeToAscii(line.strip()) for line in some_file]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# ``LongTensor`` of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = torch.Tensor([0]) # you can also just simply use ``loss = 0``\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every ``plot_every`` ``iters``\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7f2f3d4-8c25-4d5d-9487-5d505492c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rovek\n",
      "Uakov\n",
      "Shakov\n",
      "Gerter\n",
      "Erengers\n",
      "Roun\n",
      "Sertana\n",
      "Parez\n",
      "Artana\n",
      "Cha\n",
      "Han\n",
      "Iun\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "\n",
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))\n",
    "\n",
    "samples('Russian', 'RUS')\n",
    "\n",
    "samples('German', 'GER')\n",
    "\n",
    "samples('Spanish', 'SPA')\n",
    "\n",
    "samples('Chinese', 'CHI')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
