# Deep Learning Algorithms using 


## ðŸ§  Implemented Deep Learning Models

- [x] **AutoEncoder** - A basic autoencoder for unsupervised representation learning.
- [x] **Variational Autoencoder (VAE)** - Probabilistic autoencoder with latent space sampling.
- [x] **Multilayer Perceptron (MLP)** - A simple feedforward neural network.
- [x] **Convolutional Neural Network (CNN)** - A CNN for image classification tasks.
- [x] **Deep Convolutional GAN (DCGAN)** - A convolutional GAN for generating images.
- [x] **Generative Adversarial Network (GAN)** - Basic GAN implementation with generator and discriminator.
- [x] **Recurrent Neural Network (RNN) - LSTM** - Long Short-Term Memory network for sequence modeling.
- [x] **GPT-style Transformer** - A transformer-based language model inspired by GPT.
- [x] **Bigram Language Model** - A simple language model based on bigram probabilities.



## Language Models
Pytorch implementations of various language models.

### TODOs
- [ ] GPT model to add n-digit numbers
- [ ] N-gram language model
- [ ] Recurrent neural network (RNN)
- [ ] Rapper-AI to imitate eminem

### Useful Resources
[Transformer Neural Networks Explained](https://www.youtube.com/watch?v=zxQyTK8quyY)
[Illustrated Guide to Transformers Neural Network](https://youtu.be/4Bdc55j80l8?si=TjKIcphjFMBnDtVH)

Inspired by [This Video](https://youtu.be/kCc8FmEb1nY?si=BdO4jRMAGfj6ulxV)
